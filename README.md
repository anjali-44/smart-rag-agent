# ğŸ¤– SmartAgent-QA-Bot

This is a hybrid AI chatbot that intelligently routes user questions to either a custom document vectorstore or Wikipedia search based on the topic. Built using **LangGraph**, **Groq's LLaMA 3**, **AstraDB**, and **Gradio**, it delivers fast, context-aware answers via a clean chatbot UI.

## ğŸš€ Features

- ğŸ§  **LangGraph-powered flow** with conditional routing
- ğŸ” **RAG-enabled** via AstraDB vectorstore (Cassandra)
- ğŸŒ **Fallback to Wikipedia** for general knowledge queries
- âš¡ Powered by **Groq's LLaMA 3.3-70B**
- ğŸ¨ Interactive frontend using **Gradio**

## ğŸ› ï¸ Tech Stack

- `LangGraph` â€” LLM routing and workflow engine  
- `LangChain` â€” retrieval, loading, and chaining  
- `Groq` â€” fast LLaMA-3 based LLMs  
- `AstraDB` â€” vectorstore for document indexing  
- `Gradio` â€” chatbot UI  
- `WikipediaAPIWrapper` â€” external fallback knowledge base  

## ğŸ’¡ Use Case

This chatbot can be used to:
- Query indexed technical documentation
- Fallback to Wikipedia when questions go beyond the scope
- Build intelligent LLM apps with custom + public knowledge

## ğŸ§ª Live Demo

Check out the live version here on Hugging Face Spaces:  
ğŸ”— [SmartAgent-QA-Bot](https://huggingface.co/spaces/anj12-sh/SmartAgent-QA-Bot)

## ğŸ“ Project Structure

```bash
â”œâ”€â”€ app.py               # Main app logic
â”œâ”€â”€ requirements.txt     # All dependencies
â”œâ”€â”€ .env.example         # Template for your environment variables
â””â”€â”€ README.md            # Project documentation (you are here!)



ğŸ§  How It Works

User submits a question.
The router model decides: vectorstore or Wikipedia.
If vectorstore:
Uses AstraDB to retrieve chunks
If Wikipedia:
Uses WikipediaAPIWrapper to search & extract content
A final answer is generated using Groq's LLM.
Displayed in a Gradio chatbot UI.


ğŸ“œ License
MIT License â€“ Free to use, modify, and share.

